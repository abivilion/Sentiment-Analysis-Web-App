{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis  .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6A07XNMJ-25v"
      ],
      "toc_visible": true,
      "mount_file_id": "1kcnKY-uzpHy--hcbAVOPiZzeoOdH3nfC",
      "authorship_tag": "ABX9TyPUp8nHGmkV7/RfQnGr/B3C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abivilion/Sentiment-Analysis-Web-App/blob/master/Sentiment_Analysis_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOLvvY9YDfyC"
      },
      "source": [
        "### **Goal**: Let Machine Understand the sentiments of humans by reading text data. And perform a better guess of the sentiments by choosing  highest probable sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bOYde-8dLZ3"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwokcszbdPm6"
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnVZJlTmBG81"
      },
      "source": [
        "## **Importing Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJytQpWkEook"
      },
      "source": [
        "**Yelp.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V52k4Gei_0G3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ce98c2b9-6028-49d5-f457-49c778ff0db1"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "dty= pd.read_csv('yelp.txt',sep='\\t',header=None)\n",
        "\n",
        "dty.head()\n",
        "# review and sentiment\n",
        "# 0-> negative\n",
        "# 1-> positive review\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0                           Wow... Loved this place.  1\n",
              "1                                 Crust is not good.  0\n",
              "2          Not tasty and the texture was just nasty.  0\n",
              "3  Stopped by during the late May bank holiday of...  1\n",
              "4  The selection on the menu was great and so wer...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_DFYQgCClca"
      },
      "source": [
        "Assign Columns Name "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "CBBA3OfpCioW",
        "outputId": "bcc8ac1f-cbc7-4e61-bc2d-c1ef740cb9b9"
      },
      "source": [
        "col_nm=['Review','Sentiment']\n",
        "dty.columns = col_nm\n",
        "dty.head()\n",
        "# dty.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Sentiment\n",
              "0                           Wow... Loved this place.          1\n",
              "1                                 Crust is not good.          0\n",
              "2          Not tasty and the texture was just nasty.          0\n",
              "3  Stopped by during the late May bank holiday of...          1\n",
              "4  The selection on the menu was great and so wer...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7qYnoe6EtNc"
      },
      "source": [
        "**Amazon.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Uq5z0VF-DO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0b497897-5541-4ec8-9031-c080c0763552"
      },
      "source": [
        "dta= pd.read_csv('amazon.txt',sep='\\t',header=None)\n",
        "# review and sentiment\n",
        "# 0->negative, 1-> positive for positive review\n",
        "dta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Good case, Excellent value.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Great for the jawbone.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The mic is great.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  So there is no way for me to plug it in here i...  0\n",
              "1                        Good case, Excellent value.  1\n",
              "2                             Great for the jawbone.  1\n",
              "3  Tied to charger for conversations lasting more...  0\n",
              "4                                  The mic is great.  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7B-Frx_GnF7"
      },
      "source": [
        "Assign Columns Name "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLw52cMyGp8D",
        "outputId": "551b995e-46a2-4bc5-e936-6959cf0f96cd"
      },
      "source": [
        "col_nm = ['Review','Sentiment']\n",
        "dta.columns = col_nm\n",
        "dta.head()\n",
        "dta.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiVycxU2G8id"
      },
      "source": [
        "**IMDB.txt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "oc-h-8vrHzCe",
        "outputId": "b85d080e-dd75-47ba-973f-9bd6b2e64be1"
      },
      "source": [
        "dtim= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Machine Learning/Major Project/imdb.txt',sep='\\t',header=None)\n",
        "# review and sentiment\n",
        "# 0->negative, 1-> positive for positive review\n",
        "dtim.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not sure who was more lost - the flat characte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Very little music or anything to speak of.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The best scene in the movie was when Gerardo i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0  1\n",
              "0  A very, very, very slow-moving, aimless movie ...  0\n",
              "1  Not sure who was more lost - the flat characte...  0\n",
              "2  Attempting artiness with black & white and cle...  0\n",
              "3       Very little music or anything to speak of.    0\n",
              "4  The best scene in the movie was when Gerardo i...  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us9rQZGuIG9v"
      },
      "source": [
        "Assign Columns Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV1MWVP5ILOE",
        "outputId": "c7e0e01c-c24f-4111-fc43-b5d060c2b93b"
      },
      "source": [
        "col_nm = ['Review','Sentiment']\n",
        "dtim.columns = col_nm\n",
        "dtim.head()\n",
        "dtim.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(748, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVB91-5kIzeM"
      },
      "source": [
        "### **Mega DataSet** \n",
        "Adding sets all in one set(yelp <- amazon <- imdb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo8bhin4JPiI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "15cd613b-3096-4252-d744-e7ee1179287f"
      },
      "source": [
        "data = dty.append([dta,dtim],ignore_index=True)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2743</th>\n",
              "      <td>I just got bored watching Jessice Lange take h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2744</th>\n",
              "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2745</th>\n",
              "      <td>In a word, it is embarrassing.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2746</th>\n",
              "      <td>Exceptionally bad!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2747</th>\n",
              "      <td>All in all its an insult to one's intelligence...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2748 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Review  Sentiment\n",
              "0                              Wow... Loved this place.          1\n",
              "1                                    Crust is not good.          0\n",
              "2             Not tasty and the texture was just nasty.          0\n",
              "3     Stopped by during the late May bank holiday of...          1\n",
              "4     The selection on the menu was great and so wer...          1\n",
              "...                                                 ...        ...\n",
              "2743  I just got bored watching Jessice Lange take h...          0\n",
              "2744  Unfortunately, any virtue in this film's produ...          0\n",
              "2745                   In a word, it is embarrassing.            0\n",
              "2746                               Exceptionally bad!            0\n",
              "2747  All in all its an insult to one's intelligence...          0\n",
              "\n",
              "[2748 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH_0bMlDKqjs",
        "outputId": "77d79957-6642-4a60-e24e-dde9a4798427"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2748, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBZzH_GoKvfE"
      },
      "source": [
        "*Distribution Of Sentiments Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQaUzuLZLABh",
        "outputId": "6c38e8e5-c501-43d5-f81b-83d8d0e8dee8"
      },
      "source": [
        " data['Sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1386\n",
              "0    1362\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9F41J-8NJ1_"
      },
      "source": [
        "*Null Checking*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv4b-O2RNP-v",
        "outputId": "daa01ce2-aa93-4a43-ace9-35daaa47ee3a"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review       0\n",
              "Sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8Z2CWXuN2GL",
        "outputId": "bfd6dc39-dd4e-4a8c-b458-558b0fbf5b08"
      },
      "source": [
        "x = data['Review']\n",
        "y = data['Sentiment']\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2748,)\n",
            "(2748,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l89ATcPBOXL-"
      },
      "source": [
        "## **Data Preprocessing/Cleaning**\n",
        "\n",
        "Here, Stopwords, Punctuations -> **REMOVED**\n",
        "\n",
        "Apply ***Lemmatization***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kYig-lBOe7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "102eac59-3263-4954-dd52-9ae25890d4f3"
      },
      "source": [
        "\n",
        " punct = string.punctuation\n",
        " punct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20r4EGgkTh2u"
      },
      "source": [
        "Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vFfMbMaTmtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e337f96-a579-4604-fca3-95803bfe7e43"
      },
      "source": [
        "stopwords= list(STOP_WORDS) #list of stopwords\n",
        "stopwords  #326 words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['how',\n",
              " 'several',\n",
              " '’re',\n",
              " 'him',\n",
              " 'whenever',\n",
              " 'really',\n",
              " 'together',\n",
              " 'two',\n",
              " 'something',\n",
              " 'after',\n",
              " 'whole',\n",
              " 'once',\n",
              " 'sometime',\n",
              " 'full',\n",
              " 'whoever',\n",
              " 'put',\n",
              " 'hereby',\n",
              " 'yourselves',\n",
              " 'his',\n",
              " 'hence',\n",
              " 'cannot',\n",
              " 'first',\n",
              " 'beyond',\n",
              " 'already',\n",
              " 'over',\n",
              " 'can',\n",
              " '‘ve',\n",
              " 'else',\n",
              " 'within',\n",
              " 'does',\n",
              " 'latter',\n",
              " 'thereby',\n",
              " 'noone',\n",
              " 'seems',\n",
              " 'indeed',\n",
              " 'at',\n",
              " 'part',\n",
              " 'only',\n",
              " 'without',\n",
              " 'although',\n",
              " 'everything',\n",
              " 'such',\n",
              " 'seem',\n",
              " 'a',\n",
              " 'hereupon',\n",
              " 'none',\n",
              " 'along',\n",
              " 'regarding',\n",
              " 'among',\n",
              " 'besides',\n",
              " 'neither',\n",
              " 'ca',\n",
              " 'back',\n",
              " 'who',\n",
              " 'becomes',\n",
              " 'whose',\n",
              " 'upon',\n",
              " 'when',\n",
              " 'another',\n",
              " 'before',\n",
              " 'say',\n",
              " 'go',\n",
              " 'well',\n",
              " '‘ll',\n",
              " 'all',\n",
              " 'if',\n",
              " 'eleven',\n",
              " 'itself',\n",
              " \"'re\",\n",
              " 'hundred',\n",
              " 'hers',\n",
              " 'themselves',\n",
              " 'sixty',\n",
              " 'just',\n",
              " 'had',\n",
              " 'herein',\n",
              " 'forty',\n",
              " 'am',\n",
              " 'seeming',\n",
              " 'she',\n",
              " 'namely',\n",
              " 'has',\n",
              " 'their',\n",
              " 'fifty',\n",
              " 'into',\n",
              " 'alone',\n",
              " 'yet',\n",
              " 'somewhere',\n",
              " 'latterly',\n",
              " 'did',\n",
              " 'here',\n",
              " 'nor',\n",
              " 'across',\n",
              " 'myself',\n",
              " 'whither',\n",
              " 'move',\n",
              " 'also',\n",
              " 'somehow',\n",
              " 'were',\n",
              " 'every',\n",
              " 'her',\n",
              " 'too',\n",
              " 'whether',\n",
              " 'used',\n",
              " 'own',\n",
              " 'for',\n",
              " 'toward',\n",
              " 'rather',\n",
              " 'anywhere',\n",
              " 'your',\n",
              " 'its',\n",
              " 'of',\n",
              " 'to',\n",
              " '‘d',\n",
              " 'three',\n",
              " 'behind',\n",
              " 'last',\n",
              " 'around',\n",
              " 'do',\n",
              " 'top',\n",
              " 'nine',\n",
              " 'amongst',\n",
              " 'from',\n",
              " 'thru',\n",
              " \"'ll\",\n",
              " 'himself',\n",
              " 're',\n",
              " 'again',\n",
              " 'where',\n",
              " '’ll',\n",
              " 'down',\n",
              " 'wherein',\n",
              " 'must',\n",
              " 'until',\n",
              " 'otherwise',\n",
              " 'very',\n",
              " 'whatever',\n",
              " 'serious',\n",
              " 'me',\n",
              " 'nothing',\n",
              " 'either',\n",
              " \"'d\",\n",
              " 'nobody',\n",
              " 'no',\n",
              " 'always',\n",
              " 'could',\n",
              " 'name',\n",
              " 'an',\n",
              " 'then',\n",
              " 'should',\n",
              " 'ourselves',\n",
              " 'yourself',\n",
              " 'seemed',\n",
              " 'though',\n",
              " 'you',\n",
              " 'since',\n",
              " '’s',\n",
              " 'there',\n",
              " 'whereby',\n",
              " 'why',\n",
              " '‘m',\n",
              " 'this',\n",
              " 'which',\n",
              " 'five',\n",
              " 'anything',\n",
              " 'been',\n",
              " 'other',\n",
              " 'us',\n",
              " 'side',\n",
              " 'but',\n",
              " 'whereupon',\n",
              " 'next',\n",
              " 'others',\n",
              " 'might',\n",
              " 'hereafter',\n",
              " 'ever',\n",
              " 'beforehand',\n",
              " 'thereafter',\n",
              " 'call',\n",
              " 'via',\n",
              " 'everyone',\n",
              " 'ours',\n",
              " 'any',\n",
              " 'some',\n",
              " 'therefore',\n",
              " 'out',\n",
              " '‘s',\n",
              " 'eight',\n",
              " 'because',\n",
              " \"'ve\",\n",
              " 'herself',\n",
              " 'few',\n",
              " 'thus',\n",
              " 'throughout',\n",
              " 'below',\n",
              " 'most',\n",
              " 'the',\n",
              " 'anyone',\n",
              " 'therein',\n",
              " 'off',\n",
              " 'above',\n",
              " 'whereafter',\n",
              " 'someone',\n",
              " 'yours',\n",
              " 'anyhow',\n",
              " 'empty',\n",
              " 'it',\n",
              " 'fifteen',\n",
              " 'by',\n",
              " 'towards',\n",
              " 'various',\n",
              " 'front',\n",
              " 'will',\n",
              " 'whence',\n",
              " 'being',\n",
              " 'moreover',\n",
              " \"'s\",\n",
              " 'would',\n",
              " 'anyway',\n",
              " 'ten',\n",
              " 'both',\n",
              " 'nevertheless',\n",
              " 'n‘t',\n",
              " 'thence',\n",
              " 'due',\n",
              " 'those',\n",
              " 'with',\n",
              " 'we',\n",
              " 'is',\n",
              " 'get',\n",
              " 'keep',\n",
              " 'per',\n",
              " 'done',\n",
              " '’m',\n",
              " 'much',\n",
              " 'however',\n",
              " 'are',\n",
              " 'bottom',\n",
              " 'still',\n",
              " 'more',\n",
              " 'four',\n",
              " 'twenty',\n",
              " 'was',\n",
              " 'he',\n",
              " 'onto',\n",
              " 'least',\n",
              " 'up',\n",
              " 'be',\n",
              " 'or',\n",
              " 'and',\n",
              " 'in',\n",
              " 'less',\n",
              " 'quite',\n",
              " 'thereupon',\n",
              " 'show',\n",
              " 'made',\n",
              " 'using',\n",
              " 'during',\n",
              " 'while',\n",
              " 'perhaps',\n",
              " 'about',\n",
              " 'each',\n",
              " 'make',\n",
              " 'never',\n",
              " 'may',\n",
              " 'see',\n",
              " 'now',\n",
              " 'six',\n",
              " 'whereas',\n",
              " 'twelve',\n",
              " 'many',\n",
              " 'sometimes',\n",
              " 'even',\n",
              " 'everywhere',\n",
              " 'same',\n",
              " 'as',\n",
              " 'on',\n",
              " 'former',\n",
              " 'often',\n",
              " 'give',\n",
              " 'become',\n",
              " 'became',\n",
              " \"'m\",\n",
              " '‘re',\n",
              " 'almost',\n",
              " 'except',\n",
              " 'these',\n",
              " 'unless',\n",
              " 'wherever',\n",
              " 'so',\n",
              " 'elsewhere',\n",
              " 'enough',\n",
              " 'that',\n",
              " 'between',\n",
              " 'through',\n",
              " 'further',\n",
              " 'than',\n",
              " \"n't\",\n",
              " 'whom',\n",
              " 'them',\n",
              " 'against',\n",
              " 'amount',\n",
              " 'take',\n",
              " 'afterwards',\n",
              " 'n’t',\n",
              " 'doing',\n",
              " 'my',\n",
              " 'one',\n",
              " 'i',\n",
              " '’ve',\n",
              " 'please',\n",
              " 'our',\n",
              " 'third',\n",
              " 'have',\n",
              " 'not',\n",
              " 'what',\n",
              " 'they',\n",
              " 'mine',\n",
              " 'meanwhile',\n",
              " 'formerly',\n",
              " 'nowhere',\n",
              " 'under',\n",
              " 'mostly',\n",
              " 'beside',\n",
              " '’d',\n",
              " 'becoming']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvVtV5NZW2T1"
      },
      "source": [
        "***Data Cleaning Method***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul4pJejwiDT0"
      },
      "source": [
        "nlp= spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNNDllPwW7PH"
      },
      "source": [
        "def text_cleaning(vario): # accept only 1 review at a run\n",
        "  doc = nlp(vario) # calling spacy model to work on a SENTENCE \n",
        "  \n",
        "  tokens = [] # list of tokens\n",
        "\n",
        "  # lowering case all tokens \n",
        "  \n",
        "  for token in doc:\n",
        "\n",
        "# if root form(token) of that word is not pronoun then it is going to convert that into lowercase\n",
        "    if token.lemma_ !=\"-PRON-\":\n",
        "      temp = token.lemma_.lower().strip()\n",
        "    else:\n",
        "# If that word is proper noun,then it directly taking lower case, because there is no lemma for proper noun\n",
        "      temp = token.lower_\n",
        "    tokens.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  cleaned_tokens= [] \n",
        "  # removing all punctuation and stopword tokens  \n",
        "  for token in tokens:\n",
        "    if token not in stopwords and token not in punct:\n",
        "      cleaned_tokens.append(token)\n",
        "  return cleaned_tokens          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s52ZAydoxCul"
      },
      "source": [
        "\n",
        "# text_cleaning(\"usa having Harvard University\")\n",
        "# text_cleaning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7GrxJDG7bnQ"
      },
      "source": [
        "## **Verctorization Feature Engineering(TF-IDF)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX1d-ghx7lPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5ec4ec-a9f6-4ed8-9bac-1ec4225812db"
      },
      "source": [
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=text_cleaning)\n",
        "tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=<function text_cleaning at 0x7f4ec4e534d0>,\n",
              "                use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjimqcEE-nfA"
      },
      "source": [
        "*Creating a Support Vector Classifier*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTVeaKWe-tuv"
      },
      "source": [
        "classifier = SVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A07XNMJ-25v"
      },
      "source": [
        "## **Training and Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1-bz2ol-_L1"
      },
      "source": [
        "**Spliting Data**\n",
        "\n",
        "Testing Data: 0.2 (20% of Whole)\n",
        "\n",
        "Training Data: 0.8 (80% of Whole)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCPk2J_5_Dvd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0 )\n",
        "# x_train.shape+x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETlYhO4XBTPr"
      },
      "source": [
        "**Fitting the Values/Data**\n",
        "\n",
        "*Pipeline* - The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j4-PMgaBbOQ"
      },
      "source": [
        "clf =Pipeline([('tfidf',tfidf),('clf',classifier)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw0Z6d3-Ccd1",
        "outputId": "64d00f83-a29e-444d-ac1e-f173b9bdd378"
      },
      "source": [
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function text_cleaning at 0x7f4ec4e534d0>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTAqTmGkPDqx"
      },
      "source": [
        "## **Testing and Scoring**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMftr3GxPMQA"
      },
      "source": [
        "\n",
        "y_pred = clf.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2bYqN4WPoru"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__UQRVDHPnrV",
        "outputId": "b1a7298a-74c2-45d1-ebb9-bc53061f6269"
      },
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[209,  70],\n",
              "       [ 48, 223]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E2uG2P-PzOD"
      },
      "source": [
        "**Classification Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGutCipRP26b",
        "outputId": "c859221a-d8e9-4c5a-c289-21df470a2a9a"
      },
      "source": [
        "print(classification_report(y_test,y_pred)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.75      0.78       279\n",
            "           1       0.76      0.82      0.79       271\n",
            "\n",
            "    accuracy                           0.79       550\n",
            "   macro avg       0.79      0.79      0.79       550\n",
            "weighted avg       0.79      0.79      0.79       550\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coxYfMHFQF6w"
      },
      "source": [
        "**Accuracy Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuEBtO_zQJBl",
        "outputId": "4cf269a2-2e8a-4082-98b8-fefb28a7dbc4"
      },
      "source": [
        "print(f'Accuracy Score: {round((accuracy_score(y_test,y_pred)*100),2)}%')\n",
        "# 78.55%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 78.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkAjgLjBRGjM"
      },
      "source": [
        "**Checking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8eZIT0RJoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05eea21-275d-4b83-dfab-58fe98507239"
      },
      "source": [
        "examine= \"looping is best a way  safe \"\n",
        "print(clf.predict([examine]))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "   text_cleaning\n",
        "   clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4hOZICZz4C3"
      },
      "source": [
        "# clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pChJWbEnt79N"
      },
      "source": [
        "### **Saving The Trained Model file**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWcHWQuht7SO",
        "outputId": "b799c560-757e-469a-e7e9-9f34fff7be5d"
      },
      "source": [
        "joblib.dump(clf,'Sentai')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sentai']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQqDJVUMVo4x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}